{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1fbbf-b4a1-4565-8750-c50bf8fe313f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "import subprocess\n",
    "import glob\n",
    "import random\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "from radiant_mlhub import Dataset, get_session\n",
    "from urllib.parse import urlparse\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0377360-4ee2-4287-8070-0e5139f758eb",
   "metadata": {},
   "source": [
    "#### Access MLHUB API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b50cd-9ecf-4fcf-9c85-71ee8e81d2bf",
   "metadata": {},
   "source": [
    "connect to the API and fetch the landcovernet collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59402f6d-18e7-4498-be2d-fb2a3444b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MLHUB_API_KEY'] = '31d9dc2064d0be58b464666ca085b50856a3df59534d244c48a42bc5f5f82722'\n",
    "session = get_session()\n",
    "# ref_landcovernet_na_v1 is for North America\n",
    "# ref_landcovernet_af_v1 is for Africa \n",
    "# ...\n",
    "dataset = Dataset.fetch('ref_landcovernet_na_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807cae5-7dfd-4156-9e73-f586c3099ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print dataset metadata and collections\n",
    "print(f'Title: {dataset.title}')\n",
    "print(f'DOI: {dataset.doi}')\n",
    "print(f'Citation: {dataset.citation}')\n",
    "print('\\nCollection IDs and License:')\n",
    "for collection in dataset.collections:\n",
    "    print(f'    {collection.id} - {collection.license}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c304b0f5-0629-4300-a064-fef15b5b0843",
   "metadata": {},
   "source": [
    "create main folder where to save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71f7fe-f88b-4d79-b9bb-7531ac9969e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "WDIR = \"dataset/\"\n",
    "if not os.path.exists(WDIR):\n",
    "    os.mkdir(WDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97687abf-f629-4e95-bda8-9e5deb4802a0",
   "metadata": {},
   "source": [
    "#### Labels: from MLHUB, download landcovernet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d0ea2-ecca-4347-8ea7-38157fd033bd",
   "metadata": {},
   "source": [
    "Download dataset locally - only labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95585f50-5034-4792-a873-ea2a081506be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_tarfile = dataset.collections.labels[0].download(WDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b99394b-1432-471d-ba3e-cde56104e035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract labels into current directory\n",
    "with tarfile.open(labels_tarfile, \"r\") as tar:\n",
    "    tar.extractall(path = WDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597dfcdc-ba9b-470e-ab38-35bbfde8709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extracted tarfile\n",
    "os.remove(labels_tarfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f581b7-d578-4866-82f3-c0869e623cc5",
   "metadata": {},
   "source": [
    "get rid of alpha band, save to tif, translate to numpy array, delete original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb0fe0-459b-4e6a-bda3-5c3af7105d18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_folder = WDIR + \"ref_landcovernet_na_v1_labels\"\n",
    "\n",
    "# create labels folder\n",
    "if not os.path.exists(WDIR + \"labels\"):\n",
    "    os.mkdir(WDIR + \"labels\")\n",
    "    \n",
    "# loop through labels tif files\n",
    "for label in os.scandir(labels_folder):\n",
    "    if not label.is_dir():\n",
    "        continue\n",
    "    if label.path == WDIR + 'ref_landcovernet_na_v1_labels/_common':\n",
    "        continue\n",
    "\n",
    "    dates = pd.read_csv(label.path+\"/source_dates.csv\")\n",
    "    \n",
    "    # get only band zero and drop it into a numpy array\n",
    "    for date in dates[dates.columns[-1]].values:\n",
    "        tif_out = WDIR + f\"labels/{label.name[-15:]}_{date}.tif\"\n",
    "        npy_out = WDIR + f\"labels/{label.name[-15:]}_{date}\"\n",
    "        if not os.path.exists(npy_out):\n",
    "            subprocess.run([\"gdal_translate\", \"-b\", \"1\",\n",
    "                          f\"{label.path}/labels.tif\", tif_out])\n",
    "            ds = gdal.Open(tif_out)\n",
    "            im = ds.GetRasterBand(1).ReadAsArray()\n",
    "            os.remove(tif_out)\n",
    "            np.save(npy_out,im)\n",
    "\n",
    "    #delete previous folder (label.path)\n",
    "    shutil.rmtree(label.path)\n",
    "# remove old folder labels\n",
    "shutil.rmtree(labels_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67910a3-5434-4a21-bda8-ea3ce4feb924",
   "metadata": {},
   "source": [
    "quick labels sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afba87b-3597-4fa5-9986-7366a27e5a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a random npy label file, show image\n",
    "file = random.choice(os.listdir(WDIR + 'labels'))\n",
    "im = np.load(file)\n",
    "c_map = cm.get_cmap('rainbow')\n",
    "c_map.set_bad('green')\n",
    "b = im.astype('float32').copy()\n",
    "b[b==5] = np.nan\n",
    "plt.imshow(b, cmap=c_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237855d3-6e41-48a8-a650-5f4cd545c168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43ea2a71-e40a-4ac8-aca3-5369616136ca",
   "metadata": {},
   "source": [
    "#### Landsat images: from MLHUB, download landcovernet images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f9511-9ebc-4a5e-b66e-1b738ba228ee",
   "metadata": {},
   "source": [
    "Download zipped dataset locally - only Landsat images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75efe31-f2a1-4012-8729-0a8926dde96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download zipped landsat colletion\n",
    "images_tarfile = dataset.collections.source_imagery[2].download(output_dir=WDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058626cd-8a33-4e7c-9c43-29245fb08176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract images into current directory\n",
    "with tarfile.open('dataset/ref_landcovernet_na_v1_source_landsat_8.tar.gz', \"r\") as tar:\n",
    "    tar.extractall(path = WDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b0c57-c292-4c3e-bfed-067a9bfcf20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tarfile\n",
    "os.remove(images_tarfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55c05d-3592-4860-970d-072553c7ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzipped Landsat images folder\n",
    "images_folder = WDIR + \"ref_landcovernet_na_v1_source_landsat_8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66266678-a117-4075-a3ce-9facf3c9e097",
   "metadata": {},
   "source": [
    "get only 6 bands (RGB + NIR + 2 SWIR bands), save to file as a stacked numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1164c-e690-425d-806f-a5209e379266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create Landsat images folder\n",
    "if not os.path.exists(WDIR + \"images\"):\n",
    "    os.mkdir(WDIR + \"images\")\n",
    "\n",
    "# loop through images tif files\n",
    "for image in os.scandir(images_folder):   \n",
    "    if not image.is_dir():\n",
    "        continue\n",
    "    if len(glob.glob(image.path + '/*.tif')) == 0:\n",
    "        print(f'no bands path: {image.path}')\n",
    "        continue\n",
    "    \n",
    "    # get 6 out of 7 bands, save stack image to npy array\n",
    "    # -- get rid of coastal band\n",
    "    # -- red, green, blue, NIR, SWIR16, SWIR22\n",
    "    npy_out = WDIR + f\"images/image_{image.name[-17:]}\" \n",
    "    if not os.path.exists(npy_out + '.npy'):\n",
    "        \n",
    "        tif_out = WDIR + f\"images/image_{image.name[-17:]}.tif\"\n",
    "        subprocess.run([\"gdal_merge.py\", \"-separate\", \"-o\",\n",
    "                tif_out,\n",
    "                \"-of\",\"GTiff\", f\"{image.path}/B02.tif\",\n",
    "                f\"{image.path}/B03.tif\",f\"{image.path}/B04.tif\",f\"{image.path}/B05.tif\",\n",
    "                f\"{image.path}/B06.tif\",f\"{image.path}/B07.tif\"])\n",
    "\n",
    "        ds = gdal.Open(tif_out)\n",
    "        array = []\n",
    "        for b in range(1, ds.RasterCount+1):\n",
    "            im = ds.GetRasterBand(b).ReadAsArray()\n",
    "            array.append(im)\n",
    "            \n",
    "        os.remove(tif_out)\n",
    "        array_stack = np.stack(array)\n",
    "        np.save(npy_out, array_stack)\n",
    "\n",
    "# remove old folder images\n",
    "shutil.rmtree(images_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3cae5-42a6-456c-8372-8effc5c556af",
   "metadata": {},
   "source": [
    "Landsat images sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd614bb0-033f-4fce-a851-8b12dd0d1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random npy image file, show image\n",
    "file = random.choice(os.listdir(WDIR + 'images'))\n",
    "im = np.load(WDIR + 'images/' + file)[3] # show NIR band\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8f758-39d6-4a27-8eaa-f59459cb16de",
   "metadata": {},
   "source": [
    "#### Labels and Landsat images: save dataset subset containing only images with 20-85% of pixels labeled as forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a02878-bc49-4e4a-9d3a-6c6c62928f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_percentage(label):\n",
    "    per = np.sum(label==5)/label.flatten().shape[0]\n",
    "    return per\n",
    "\n",
    "def acceptable_levels_of_forest(label,up=0.85,low=0.2):\n",
    "    \"\"\"Returns True if forest percentage in a given image has\n",
    "    forest percentage between up and low\n",
    "    \"\"\"\n",
    "    per = forest_percentage(label)\n",
    "    if per>=low and per<=up:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_list_ids(prefix=\"dataset\"):\n",
    "    #Get images\n",
    "    labels_id = glob.glob(prefix+'/labels/*.npy')\n",
    "    images_id = glob.glob(prefix+'/images/*.npy')\n",
    "    list_id = np.intersect1d([image[-21:] for image in images_id],\n",
    "                             [label[-21:] for label in labels_id])\n",
    "    return list_id, len(list_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3ffc6-1f64-42a7-b53d-2c843d79b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_images = \"data_forest_20_85/images/\"\n",
    "if not os.path.exists(out_images):\n",
    "    os.mkdir(out_images)\n",
    "    \n",
    "out_labels = \"data_forest_20_85/labels/\"\n",
    "if not os.path.exists(out_labels):\n",
    "    os.mkdir(out_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e88ed34-933f-4218-b1c8-f38600128763",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"dataset\"\n",
    "list_id,_ = get_list_ids(prefix=prefix)\n",
    "for n in list_id:\n",
    "    label_path = f'{prefix}/labels/labels_{n}'\n",
    "    image_path = f'{prefix}/images/image_{n}'\n",
    "    label = np.load(label_path)\n",
    "    if acceptable_levels_of_forest(label):\n",
    "        shutil.copyfile(label_path, out_labels + f'labels_{n}')\n",
    "        shutil.copyfile(image_path, out_images + f'image_{n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2120ee1e-66d9-401d-8d0d-15c59377b177",
   "metadata": {},
   "source": [
    "#### Labels: move landcovernet into a S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aaed47-6fc9-49c5-9860-b8e4d3b47d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define in which bucket to save the files\n",
    "bucket = \"landcoverchangedetection\"\n",
    "# get list of labels paths\n",
    "files = glob.glob('dataset/labels/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc346cd-7bb9-4d32-b7c6-21b53786b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all labels in S3 bucket\n",
    "folder = 'dataset/labels'\n",
    "for file in files:\n",
    "    file = file[12:]\n",
    "    path = os.path.join(folder, file)\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(path).upload_file(path)\n",
    "    os.remove(path)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c103ed-9511-4e25-ab4d-f9e7fa3ca0a3",
   "metadata": {},
   "source": [
    "#### Landsat images: move landcovernet into S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39413b-b6c4-4355-9d9f-be7dad1299d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define in which bucket to save the files\n",
    "bucket = \"landcoverchangedetection\"\n",
    "# get list of images paths\n",
    "files = glob.glob('dataset/images/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b554008-fee3-45c7-87c4-4cb76aae09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all labels in S3 bucket\n",
    "folder = 'dataset/images'\n",
    "for file in files:\n",
    "    file = file[12:]\n",
    "    path = os.path.join(folder, file)\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(path).upload_file(path)\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374c2fd6-41b0-447c-a03c-0fc9aa4940c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Get only Labels and Landsat images with forest, save all in a second s3 folder (NOT NEEDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a725f3-fa2c-458a-84b1-666192e23c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"landcoverchangedetection\"\n",
    "s3 = boto3.resource(\"s3\")\n",
    "my_bucket = s3.Bucket(bucket)\n",
    "client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3faf9e1-ff34-4a1d-ac26-55f4d5cde144",
   "metadata": {},
   "source": [
    "create the list of labels IDs from the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356e01e-fe73-4e1c-9c8e-ae27b2e378c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_id = []\n",
    "for object in my_bucket.objects.filter(Prefix='dataset/labels'):\n",
    "    labels_id.append(object.key[15:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31747c70-e21d-4c26-96f0-c269a7776146",
   "metadata": {},
   "source": [
    "get the s3 path of labels containing forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62401cd-d50c-4b5a-a173-257953593a41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "for object in my_bucket.objects.filter(Prefix='dataset/labels/'):\n",
    "    s3_url = f\"s3://{bucket}/{object.key}\"\n",
    "    bytes_ = io.BytesIO()\n",
    "    parsed_s3 = urlparse(s3_url)\n",
    "    client.download_fileobj(Fileobj=bytes_, Bucket=parsed_s3.netloc, \n",
    "                                    Key=parsed_s3.path[1:])\n",
    "    bytes_.seek(0)\n",
    "    X_ = np.load(bytes_, allow_pickle=True)\n",
    "    if 5 in X_:\n",
    "        lst.append(object.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da10dc4-10d0-4051-83a5-bdd09f82ead8",
   "metadata": {},
   "source": [
    "move all the labels contaning forest in a different bucket division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d979987-0bc3-4f6f-87df-f764fa9b6e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in lst:\n",
    "    file = path[-21:]\n",
    "    copy_source = {\n",
    "        'Bucket': 'landcoverchangedetection',\n",
    "        'Key': 'dataset/labels/labels_' + file\n",
    "    }\n",
    "\n",
    "    bucket = s3.Bucket('landcoverchangedetection')\n",
    "\n",
    "    bucket.copy(copy_source, 'dataset_with_forest/labels/labels_' + file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526cce12-e5f7-451f-8ed6-113ed32d5e9b",
   "metadata": {},
   "source": [
    "move all Landsat images which labels contain forest in a different bucket division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3494bf7-4fe5-4af3-bb05-2556442fd2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in lst:\n",
    "    file = path[-21:]\n",
    "    copy_source = {\n",
    "        'Bucket': 'landcoverchangedetection',\n",
    "        'Key': 'dataset/images/image_' + file\n",
    "    }\n",
    "\n",
    "    bucket = s3.Bucket('landcoverchangedetection')\n",
    "\n",
    "    bucket.copy(copy_source, 'dataset_with_forest/images/image_' + file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f1c31-5fd2-4202-9c80-03856c98171e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env: earth-observation] (earth-observation2/latest)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-2:458428816525:image/earth-observation2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
