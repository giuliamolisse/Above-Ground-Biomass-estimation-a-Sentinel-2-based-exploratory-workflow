{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97f2c9-b703-40e5-8672-72a563165135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils.np_utils import to_categorical   \n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from train_once import train_random_image\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import boto3\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "# import customized functions\n",
    "import utils\n",
    "\n",
    "# import external losses \n",
    "# to be double checked\n",
    "from losses import binary_dice_coef_loss, binary_focal_loss\n",
    "\n",
    "# reload utils to update changes of .py file\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259a6c4-c507-4a71-87a5-1be35fd6b111",
   "metadata": {},
   "source": [
    "#### Define losses and metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f39543-df4b-473e-beaf-8ff513d67b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define other losses and coefficients\n",
    "# to be double checked\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def iou_coef_loss(y_true, y_pred):\n",
    "    return -iou_coef(y_true, y_pred)\n",
    "\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred) \n",
    "\n",
    "def jacard_loss(y_true, y_pred, smooth=1e-5):\n",
    "    \"\"\" Calculates mean of Jaccard distance as a loss function \"\"\"\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=(1,2))\n",
    "    sum_ = tf.reduce_sum(y_true + y_pred, axis=(1,2))\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    jd =  (1 - jac) #* smooth\n",
    "    return tf.reduce_mean(jd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae5ad8-40b2-489c-880e-5c4abb461405",
   "metadata": {},
   "source": [
    "#### Get list containing labels and images IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e607d3-0940-4813-956f-03a781210549",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'data_forest_20_85'\n",
    "#Get images\n",
    "labels_id = glob.glob(prefix+'/labels/*.npy')\n",
    "images_id = glob.glob(prefix+'/images/*.npy')\n",
    "list_id = np.intersect1d([image[-21:] for image in images_id],\n",
    "                         [label[-21:] for label in labels_id])\n",
    "n_samples = len(list_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a687d40-4cd9-494d-bf1f-dcd7e3e1387c",
   "metadata": {},
   "source": [
    "#### Define UNET for binary semantic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87118e5c-144c-49ff-989f-413d3b91c9b9",
   "metadata": {},
   "source": [
    "Define a function that build the UNET. 2 generators are created, one for the training and one for the testing data. run_model() saves the model loss to a logger at every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b75b7fc-1ae2-4189-85b0-77c70ac91386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(list_id, train_indexes, test_indexes,\n",
    "              loss_name = \"jacard_loss\",\n",
    "              loss = jacard_loss,prefix=prefix,\n",
    "              batch_size=32, img_dim = 256,\n",
    "              epochs = 5, n_channels = 6):\n",
    "    steps = len(train_indexes)//batch_size\n",
    "    input_shape = (img_dim, img_dim, n_channels)\n",
    "    \n",
    "    train_generator = utils.DataGenerator(\n",
    "        list_id[train_indexes],\n",
    "        batch_size=batch_size,\n",
    "        prefix = prefix,\n",
    "        n_channels = n_channels\n",
    "    )\n",
    "\n",
    "    test_generator = utils.DataGenerator(\n",
    "        list_id[test_indexes],\n",
    "        batch_size=batch_size,\n",
    "        prefix = prefix,\n",
    "        n_channels = n_channels\n",
    "    )\n",
    "\n",
    "\n",
    "    #val generator\n",
    "    model = utils.build_unet(input_shape)\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "                  loss = [loss],\n",
    "                  metrics=[jacard_coef, 'accuracy', 'binary_crossentropy'])\n",
    "\n",
    "    history = model.fit(train_generator,\n",
    "                        validation_data=test_generator,\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch = steps,\n",
    "                       callbacks=[Logger(loss_name)])\n",
    "    \n",
    "    return history, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a26c00-f194-47d7-a76c-88eb679cde9f",
   "metadata": {},
   "source": [
    "Define a logger. This will update a .csv file once every epoch is compleated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489fe9e-b028-484b-98c8-b46a7d79151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, loss_function_name):\n",
    "        super().__init__()\n",
    "        self.loss_name = loss_function_name\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        with open('logger.txt', 'a') as f:\n",
    "            f.write(f\"===================== START: {self.loss_name} ======================\\n\")\n",
    "            \n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        with open('logger.txt', 'a') as f:\n",
    "            f.write(f\"Epoch {epoch}/50. Val Jaccard Coef: {logs['val_jacard_coef']}\\n\")\n",
    "       \n",
    "    def on_train_end(self, logs=None):\n",
    "        with open('logger.txt', 'a') as f:\n",
    "            f.write(f\"======================= END: {self.loss_name} =======================\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf65dd3-3004-4157-b46b-a98f1340fc5e",
   "metadata": {},
   "source": [
    "#### Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a35ff7-13ac-46ee-a8fe-34047e344ec6",
   "metadata": {},
   "source": [
    "Run 3 models, each with a different loss: jacard, dice and focal. Use a train/test ratio of 80/20. Save history and model to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a2436-f006-47f3-ac8b-2faad5aa257c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"jacard\" : jacard_loss,\n",
    "    \"dice_loss\" : binary_dice_coef_loss(),\n",
    "    \"focal_loss\" : binary_focal_loss(0.25),\n",
    "}\n",
    "\n",
    "train_indexes, test_indexes = train_test_split(np.arange(n_samples),\n",
    "                                               test_size=0.2,\n",
    "                                              shuffle = True)\n",
    "\n",
    "for loss_name in losses.keys():\n",
    "    hist,model = run_model(list_id,\n",
    "                           train_indexes,\n",
    "                           test_indexes,\n",
    "                           loss_name = loss_name,\n",
    "                           loss=losses[loss_name],\n",
    "                           epochs = 40\n",
    "                    )\n",
    "    with open(f'models/{loss_name}.json', 'w') as fp:\n",
    "        json.dump(hist.history, fp)\n",
    "    model.save(f\"models/{loss_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f642274-0bc2-44ae-ae8c-ddbcfa70e6cc",
   "metadata": {},
   "source": [
    "#### Model predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dfbc13-b06f-4c97-b16b-31b3cacbe108",
   "metadata": {},
   "source": [
    "read model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ce81a-7f7d-4bba-96b0-494568827730",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"models/jacard\",\n",
    "                               compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba98c6-c718-4293-a82c-b6a66c944ba1",
   "metadata": {},
   "source": [
    "Predict on a random image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d51833-aaa4-46a8-be08-98b56fa72524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ID = random.choice(list_id)\n",
    "\n",
    "fig, axs = plt.subplot_mosaic(\"ABC\", figsize=(12,8))\n",
    "axs[\"A\"].imshow(np.load(prefix+'/images/image_' + ID)[1], cmap=\"gray\")\n",
    "axs[\"A\"].set_title(\"Image\")\n",
    "\n",
    "axs[\"B\"].imshow((y_train.reshape(256,256)>=0.5).astype(int), cmap=\"gray\")\n",
    "axs[\"B\"].set_title(\"Mask\")\n",
    "\n",
    "y_preds = model.predict(X_train).reshape(256,256)\n",
    "axs[\"C\"].imshow(y_preds, cmap=\"gray\")\n",
    "axs[\"C\"].set_title(\"Predicted\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env: earth-observation] (earth-observation2/latest)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-2:458428816525:image/earth-observation2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
